# 第一章 机器学习概览
  
  过去机器学习的主要应用包括有光学字符识别(Optical Character Recognition, OCR)、垃圾邮件过滤器(spam filter)。

  学习机器学习之前，常常会听到（了解到）监督学习和无监督学习、在线学习和批量学习、基于实例学习和基于模型学习。

  ## 1.1 什么是机器学习

机器学习是一个研究领域，让计算机无须进行明确编程就具备学习能力。从 工程化角度，机器学习是：一个计算机程序利用经验E来学习任务T，性能是P，如果针对任务T的性能P随着经验E不断增长，则称为机器学习。

**训练集**：系统用来进行学习的样例。每个训练样例称作**训练实例**（或**样本**）

## 1.2 为什么使用机器学习

**数据挖掘**：使用机器学习方法挖掘大量数据来帮助发现不太明显的规律，称为数据挖掘。

机器学习适用于：

- 有解决方案但解决方案需要进行大量人工微调或需要遵循大量规则的问题：机器学习算法通常可以简化代码，相比传统方法有更好的性能。

- 传统方法难以解决的复杂问题：最好的机器学习技术也许可以找到解决方案。

- 环境有波动：机器学习算法可以适应新数据。

- 洞察复杂问题和大量数据。

## 1.3 机器学习的应用实例

分析生产线上的产品图像来对产品进行自动分类->图像分类问题->使用卷积神经网络（CNN）；
通过脑部扫描发现肿瘤->语义分割（图像中的每个像素都需要被分类）->使用卷积神经网络（CNN）；
新闻自动分类->自然语言处理（NLP），更具体地是文本分类->可以使用循环神经网络（RNN）、CNN或者Transformer；

## 1.4 机器学习系统的类型

根据是否是在监督下训练可分为：**监督学习**、**无监督学习**、**半监督学习**和**强化学习**。

根据是否能动态地进行增量学习可分为：**在线学习**和**批量学习**。

是简单地将新的数据点和已知的数据点进行匹配，还是对训练数进行模式检测然后建立一个预测模型可分为：**基于实例的学习**和**基于模型的学习**。

### 1.4.1 监督学习和无监督学习

根据训练期间接受的监督数量和监督类型，可以将机器学习系统分为以下四个主要类型：**有监督学习、无监督学习、半监督学习和强化学习**。

1. 监督学习

	在监督学习中，提供给算法的包含所需解决方案的训练集称为**标签**。
	
	**分类问题**（classfication problem）是典型的监督学习任务。例如垃圾邮件过滤器就是一个很好的示例：通过大量的电子邮件示例及其所属的**类别**（垃圾邮件还是常规邮件）进行训练，然后学习如何对新邮件进行分类。

	[图01_垃圾邮件分类的已标记训练集](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE01_%E5%9E%83%E5%9C%BE%E9%82%AE%E4%BB%B6%E5%88%86%E7%B1%BB%E7%9A%84%E5%B7%B2%E6%A0%87%E8%AE%B0%E8%AE%AD%E7%BB%83%E9%9B%86.jpg)

	另一个典型的任务是通过给定一组称为预测器的特征数据来预测一个目标数值。这种类型的任务称为**回归**（regression）。

	[图02_回归问题](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE02_%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98.jpg)

	值得注意的是，一些回归算法也可以用于分类任务，反之亦然。例如，逻辑回归就被广泛地用于分类，因为它可以输出“属于某个给定类别的概率”的值。

	常见的监督学习算法有：k-邻近算法、线性回归、逻辑回归、支持向量机（SVM）、决策树和随机森林、神经网络等。

2. 无监督学习

	无监督学习的训练数据都是**未经标记**的。
	
	常见的无监督学习算法有：

	- 聚类算法

		- k-均值算法
		- DBSCAN
		- 分层聚类分析（HCA）

	- 异常检测和新颖性检测

		- 单类SVM
		- 孤立森林

	- 可视化和降维

		- 主成分分析（PCA）
		- 核主成分分析
		- 局部线性嵌入（LLE）
		- t-分布随机近邻嵌入（t-SNE）

	- 关联学习规则

		- Apriori
		- Eclat

	[图03_聚类](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE03_%E8%81%9A%E7%B1%BB.jpg)
	
	[图04_语义聚类的t-SNE可视化示例](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE04_%E8%AF%AD%E4%B9%89%E8%81%9A%E7%B1%BB%E7%9A%84t-SNE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%A4%BA%E4%BE%8B.jpg)

	除聚类外，无监督学习算法的另一有效应用是**可视化算法**（Visualization）。
	
	以及**降维**（dimensionality reduction），降维的目的是在不丢失太多信息的前提下简化数据。方法之一是将多个相关特征合并为一个。例如，汽车里程与其使用年限存在很大的相关性，所以降维算法会将它们合并成一个代表汽车磨损的特征。这个过程叫作**特征提取**。

	另一个很重要的无监督任务是**异常检测**，例如，检测异常信用卡交易以防止欺诈。一个非常类似的任务是**新颖性检测**。它的目的是检测看起来与训练集中的所有实例不同的新实例。

	[图05_异常检测](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE05_%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B.jpg)

	还有一个常见的无监督任务是**关联规则学习**，其目的是挖掘大量数据，发现属性之间的有趣联系。

3. 半监督学习

	由于通常给数据做标记是非常耗时和昂贵的，你往往会有很多未标记的数据而很少有已标记的数据。有些算法可以处理部分已标记的数据。这被称为**半监督学习**。

	[图06_半监督学习](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE06_%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.jpg)

	**大多数半监督学习算法是无监督算法和有监督算法的结合**。例如，深度信念网络（DBN）基于一种互相堆叠的无监督组件，这个组件叫作受限玻尔兹曼机（RBM）。受限玻尔兹曼机以无监督方式进行训练，然后使用有监督学习技术对整个系统进行微调。

4. 强化学习

	强化学习则是一个非常与众不同的“巨兽”。它的学习系统（在其语境中称为智能体）能够观察环境，做出选择，执行动作，并获得回报（或者是以负面回报的形式获得惩罚）。所以它必须自行学习什么是最好的策略，从而随着时间的推移获得最大的回报。策略代表智能体在特定情况下应该选择的动作。

	[图07_强化学习](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE07_%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0.jpg)

### 1.4.2 批量学习和在线学习

	通过系统是否可以从传入的数据流中进行增量学习，可分为批量学习和在线学习。

1. 批量学习

	在**批量学习**中，系统无法进行增量学习——即必须使用所有可用数据进行训练。这需要大量时间和计算资源，所以通常都是离线完成的。离线学习就是先训练系统，然后将其投入生产环境，这时学习过程停止，它只是将其所学到的应用出来。

	如果希望批量学习系统学习新数据（例如新型垃圾邮件），需要在完整数据集（包括新数据和旧数据）的基础上重新训练系统的新版本，然后停用旧系统，用新系统取而代之。幸运的是，整个训练、评估和启动机器学习系统的过程可以很轻易地实现自动化，所以即使是批量学习系统也能够适应变化。只是需要不断地更新数据，并根据需要频繁地训练系统的新版本。

	但是使用完整数据集训练需要耗费大量的计算资源，如果数据量非常大，并且需要每天从零开始自动执行训练系统，那么可能无法应用批量学习。

2. 在线学习

	在**在线学习**中，可以循序渐进地给系统提供训练数据，逐步积累学习成果。这种提供数据的方式可以是单独的，也可以采用小批量的小组数据来进行训练。

	[图08_在线学习](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE08_%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0.jpg)

	在线学习适用于：1. **需要接收持续的数据流，同时对数据流的变化做出快速或自主的反应**；2. **针对超大数据集，一台机器内存无法完全存储，也称为核外学习**。

	warnning:**核外学习通常是离线完成的**（也就是不在实时（live）系统上），因此在线学习这个名字很容易让人产生误解。我们可以将其视为**增量学习**。

	[图09_在线学习系统处理超大数据集](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE09_%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E5%A4%84%E7%90%86%E8%B6%85%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86.jpg)

	**学习率**：在线学习系统适应不断变化的数据的速度，是在线学习系统的重要参数。

	在线学习面临的重大挑战是不良数据的问题，如果给系统输入不良数据，系统的性能将会逐渐下降。为了降低这种风险，需要密切监控系统，一旦检测到性能下降，就及时中断学习（可能还需要恢复到之前的工作状态）。当然，同时还需要监控输入数据，并对异常数据做出响应（例如，使用异常检测算法）。

### 1.4.3 基于实例的学习与基于模型的学习

1. 基于实例的学习

	基于实例的学习：系统用心学习这些示例，然后通过使用相似度度量来比较新实例和已经学习的实例（或它们的子集），从而泛化（generalize）新实例。

	[图10_基于实例的学习](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE10_%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B%E7%9A%84%E5%AD%A6%E4%B9%A0.jpg)

2. 基于模型的学习

	基于模型的学习：构建实例的模型，然后使用该模型进行**预测**。

	[图11_基于模型的学习](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE11_%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AD%A6%E4%B9%A0.jpg)

	建立模型后，还需要定义一个效用函数（utility function）来衡量模型有多好；或者定义一个成本函数（cost function）来衡量模型有多差。

	**模型选择包括选择模型的类型和完全指定它的架构**。训练一个模型意味着运行一种寻找模型参数的算法，使其最适合训练数据。

	示例1-1：使用Scikit-Learn训练并运行一个线性模型

	```python
		import matplotlib.pyplot as plt
		import numpy as np
		import pandas as pd
		import sklearn.linear_model

		# load the data
		oecd_bli = pd.read_csv("oecd_bli_2015.csv", thousands=', ')
		gdp_per_capita = pd.read_csv("gdp_per_capita.csv", thousands=', ', delimiter='\t', encoding='latin1', na_values='n/a')

		# prepare the data
		countary_states = prepare_country_states(oecd_bli, gdp_per_capita)
		X = np.c_[country_stats["GDP per capita"]]
		Y = np.c_[country_stats["Life satisfacation"]]

		# Visualize the data
		country_statss.plot(kind='scatter', x = "GDP per capita", y = "Life satisfacation")
		plt.show()

		# Select a linear model
		model = sklearn.linear_model.LinearRegression()

		# Train the model
		model.fit(X, y);

		# Make a prediction for Cyprus
		X_new = [[22578]] # Cyprus's GDP per capita
		print(model.predict(X_new)) # outputs: 
	```

	如果需要将代码中的线性回归模型替换为k-近邻回归模型，只需要：

	```python
		import sklearn.neighbors
		model = sklearn.neighbors.KNeighborRegressor(n_neighbors=3)
	```

典型机器学习项目流程：

- 研究数据

- 选择模型

- 使用训练数据进行训练

- 应用模型对新示例进行预测（推断）

## 1.5 机器学习的主要挑战

总的来说，机器学习的主要任务是选择一种学习算法，对某些数据进行训练，所以最有可能出现的问题是“坏数据”和“坏算法”。

### 1.5.1 训练数据的数量不足

微软研究员的论文《数据的非理性效果》表明大数据基础上的简单算法比小数据基础上的复杂算法更加有效。

[图12_数据与算法的重要性](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE12_%E6%95%B0%E6%8D%AE%E4%B8%8E%E7%AE%97%E6%B3%95%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7.jpg)

### 1.5.2 训练数据不具代表性

为了很好地实现泛化，至关重要的一点是对于将要泛化的新示例来说，训练数据一定要非常**有代表性**。无论你使用的是基于实例的学习还是基于模型的学习，都是如此。

如果样本集太小，将会出现**采样噪声（sampling noise）**（即非代表性数据被选中）；而即便是非常大的样本数据，如果采样方式欠妥，也同样可能导致非代表性数据集，这就是所谓的**采样偏差（sampling bias）**。

### 1.5.3 低质量数据

针对数据集，数据清洗是很有必要的。

### 1.5.4 无关特征

只有训练数据里包含足够多的相关特征以及较少的无关特征，系统才能够完成学习。一个成功的机器学习项目，其关键部分是提取出一组好的用来训练的特征集。这个过程叫作**特征工程（feature engineering）**，包括以下几点：

- **特征选择（feature selection）**：从现有特征中选择最有用的特征进行训练；

- **特征提取（feature extraction）**：将现有特征进行整合，产生更有用的特征

- 通过收集新数据创建新特征。

### 1.5.5 过拟合训练数据

**过拟合（overfitting）**：指模型在训练数据上表现良好，但是泛化时却不尽如人意。

[图13_过拟合训练数据](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE13_%E8%BF%87%E6%8B%9F%E5%90%88%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE.jpg)

当模型相对于训练数据的数量和噪度都过于复杂时，会发生过拟合。可能的解决方案如下：

- 收集更多的训练数据。

- 减少训练数据中的噪声（例如，修复数据错误和消除异常值）。

通过约束模型使其更简单，并降低过拟合的风险，这个过程称为**正则化**。在学习时，应用正则化的程度可以通过一个**超参数**来控制。超参数是学习算法（不是模型）的参数。

**超参数必须在训练之前设置好，并且在训练期间保持不变**。如果将正则化超参数设置为非常大的值，会得到一个几乎平坦的模型（斜率接近零）。学习算法虽然肯定不会过拟合训练数据，但是也更加不可能找到一个好的解决方案。调整超参数是构建机器学习系统非常重要的组成部分。

[图14_正则化降低了过拟合的风险](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter1/%E5%9B%BE14_%E6%AD%A3%E5%88%99%E5%8C%96%E9%99%8D%E4%BD%8E%E4%BA%86%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E9%A3%8E%E9%99%A9.jpg)

### 1.5.6 欠拟合训练数据

欠拟合与过拟合相反，即对底层的数据结构来说，模型过于简单。常见解决欠拟合的主要方式有：

- 选择一个带有更多参数、更强大的模型。

- 给学习算法提供更好的特征集（特征工程）。

- 减少模型中的约束。

### 1.5.7 总结

总的来说：

- 机器学习是关于如何让机器可以更好地处理某些特定任务的理论，它从数据中学习，而无须清晰地编码规则。

- 机器学习系统有很多类型：有监督和无监督，批量的和在线的，基于实例的和基于模型的，等等。

- 在一个机器学习项目中，你从训练集中采集数据，然后将数据交给学习算法来计算。

- 如果训练集的数据太少或数据代表性不够，包含太多噪声或者被一些无关特征污染，那么系统将无法很好地工作。

## 1.6 测试与验证

了解一个模型对于新场景的泛化能力的唯一办法就是让模型真实地去处理新场景。为了更高效的对模型进行评估，通常将数据分为两部分：**训练集**和**测试集**。即训练集用来训练模型，测试集用来测试模型。

模型应对新场景的误差率称为**泛化误差**。如果训练误差很低（模型对于训练集来说很少出错），但是泛化误差很高，那么说明模型对于训练数据存在过拟合。

### 1.6.1 超参数调整和模型选择

为了防止对测试集的泛化误差进行多次度量，防止因过度针对测试集进行模型和超参数调整，而导致的模型对新数据表现较差的情况，常使用**保持验证（holdout validation）**的方法。

保持验证：即取训练集的一部分，用来评估几种候选模型并选择最佳模型。其中，新取出的数据即称为**验证集（validation set）**或称为**开发集（development set, or dev set）**。

即在简化的训练集上（即完整训练集减去验证集）训练具有各种超参数的多个模型，并且选择在验证集上表现最佳的模型。在此保持验证之后，在完整的训练集（包括验证集）上训练最佳模型，这就是最终模型。最后，在测试集上评估这个模型以获得泛化误差的估计值。

但是，如果验证集太小，则模型评估不精确，可能选择一个次优的模型；如果验证集太大，则剩余训练集将比完整的训练集小得多（在较少数据上训练候选模型不是最优方案）。常用的解决方法是：**使用许多小验证集重复进行的交叉验证**。

每个模型都在对其余数据进行训练后，在每个验证集上评估一次。通过对模型的所有评估求平均值，可以更准确地衡量模型的性能。但是有一个缺点：训练时间是验证集个数的倍数。

### 1.6.2 数据不匹配

验证集和测试集的数据必须与在生产环境中使用的数据具有相同的代表性。