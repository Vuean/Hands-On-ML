# 第十一章 训练深度神经网络

在第10章中，我们介绍了人工神经网络并训练了第一个深度神经网络。但是它们是浅层网络，只有几个隐藏层。如果你需要解决一个复杂的问题，例如检测高分辨率图像中的数百种物体，该怎么办？你可能需要训练更深的DNN，也许10层或更多层，每层包含数百个神经元，有成千上万个连接。训练深度DNN并不是在公园里散步。以下是你可能会遇到的一些问题：

- 你可能会遇到棘手的梯度消失问题或相关的梯度爆炸问题。这是在训练过程中通过DNN反向传播时，梯度变得越来越小或越来越大时发生的。这两个问题都使得较低的层很难训练。

- 对于如此大的网络，你可能没有足够的训练数据，或者做标签的成本太高。

- 训练可能会非常缓慢。

- 具有数百万个参数的模型会有严重过拟合训练集的风险，尤其是在没有足够的训练实例或噪声太大的情况下。

在本章中，我们将研究所有这些问题，并介绍解决这些问题的技术。我们从探索梯度消失和梯度爆炸问题及其一些受欢迎的解决方法开始。接下来，我们将研究迁移学习和无监督预训练，即使在标签数据很少的情况下，它们也可以帮助你解决复杂的任务。然后我们将讨论可以极大加速训练大型模型的各种优化器。最后我们将介绍一些流行的针对大型神经网络的正则化技术。

使用这些工具，你就能够训练非常深的网络。欢迎使用深度学习！

## 11.1 梯度消失与梯度爆炸问题

正如我们在第10章中讨论的那样，反向传播算法的工作原理是**从输出层到输入层，并在此过程中传播误差梯度**。一旦算法计算出成本函数相对于网络中每个参数的梯度，就可以使用这些梯度以梯度下降步骤来更新每个参数。

不幸的是，随着算法向下传播到较低层，梯度通常会越来越小。结果梯度下降更新使较低层的连接权重保持不变，训练不能收敛到一个良好的解。我们称其为**梯度消失问题**。在某些情况下，可能会出现相反的情况：梯度可能会越来越大，各层需要更新很大的权重直到算法发散为止。这是**梯度爆炸问题**，它出现在递归神经网络中（见第15章）。更笼统地说，深度神经网络很受梯度不稳定的影响，不同的层可能以不同的速度学习。

这些问题很久以前就凭经验观察到了，这也是深度神经网络在2000年代初期被大量抛弃的原因之一。目前尚不清楚是什么原因导致在训练DNN时使梯度如此不稳定，但是Xavier Glorot和Yoshua Bengio在2010年的一篇论文中阐明了一些观点。作者发现了一些疑点，包括流行的逻辑sigmoid激活函数和当时最流行的权重初始化技术（即平均值为0且标准差为1的正态分布）。简而言之，它们表明使用此激活函数和此初始化方案，每层输出的方差远大于其输入的方差。随着网络的延伸，方差在每一层之后都会增加，直到激活函数在顶层达到饱和为止。实际上，由于逻辑函数的平均值为0.5，而不是0（双曲线正切函数的平均值为0，在深度网络中的表现比逻辑函数稍微好一些），因此饱和度实际上变得更差。

查看逻辑激活函数（见图1），你可以看到，当输入变大（负数或正数）时，该函数会以0或1饱和，并且导数非常接近0。因此反向传播开始时它几乎没有梯度可以通过网络传播回去。当反向传播通过顶层向下传播时，存在的小梯度不断被稀释，因此对于底层来说，实际上什么也没有留下。

![fig01_逻辑激活函数的饱和](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter11/figures/fig01_%E9%80%BB%E8%BE%91%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%9A%84%E9%A5%B1%E5%92%8C.jpg)

### 11.1.1 Glorot和He初始化

Glorot和Bengio在它们的论文中提出了一种能显著缓解不稳定梯度问题的方法。他们指出，我们需要信号在两个方向上正确流动：**进行预测时，信号为正向；在反向传播梯度时，信号为反向**。我们既不希望信号消失，也不希望它爆炸并饱和。为了使信号正确流动，作者认为，我们需要每层输出的方差等于其输入的方差，并且我们需要在反方向时流过某层之前和之后的梯度具有相同的方差（如果你对数学细节感兴趣，请查看本论文）。除非该层具有相等数量的输入和神经元（这些数字称为该层的扇入和扇出），否则实际上不可能同时保证两者，但是Glorot和Bengio提出了一个很好的折中方案，在实践中证明很好地发挥作用：必须按照公式11-1中所述的随机初始化每层的连接权重，其中$fan_avg=(fan_in+fan_out)/2$。这种初始化策略称为Xavier初始化或者Glorot初始化，以论文的第一作者命名。

![fig02_公式11-1_Glorot初始化](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter11/figures/fig02_%E5%85%AC%E5%BC%8F11-1_Glorot%E5%88%9D%E5%A7%8B%E5%8C%96.jpg)

如果在公式11-1中你用$fan_in$替换$fan_avg$，则会得到Yann LeCun在20世纪90年代提出的初始化策略。他称其为LeCun初始化。Genevieve Orr和laus-Robert Müller甚至在其1998年出版的Neural Networks：Tricks of the Trade（Springer）一书中进行了推荐。当fanin=fanout时，LeCun初始化等效于Glorot初始化。研究人员花了十多年的时间才意识到这一技巧的重要性。使用Glorot初始化可以大大加快训练速度，这是导致深度学习成功的诀窍之一。

一些论文为不同的激活函数提供了类似的策略。这些策略的差异仅在于方差的大小以及它们使用的是$fan_avg$还是$fan_in$，如表11-1所示（对于均匀分布，只需计算$r=\sqrt{3\sigma^2}$）。ReLU激活函数的初始化策略（及其变体，包括ELU激活函数）有时简称为He初始化。本章稍后将解释SELU激活函数。它应该与LeCun初始化一起使用（最好与正态分布一起使用，如我们所见）

表11-1：每种激活函数的初始化参数

|初始化|激活函数|$\sigma^2$(正常)|
|:---:|:---:|:---:|
|Glorot|None、tanh、logistic、softmax|$1/fan_{avg}$|
|He|ReLU和变体|$2/fan_{in}$|
|LeCun|SELU|$1/fan_{in}$|

默认情况下，Keras使用具有均匀分布的Glorot初始化。创建层时，可以通过设置`kernel_initializer="he_uniform"`或`kernel_initializer="he_normal"`来将其更改为He初始化：

```python
    keras.layers.Dense(10, activation="relu", kernel_initializer="he_normal")
```

如果你要使用均匀分布但基于fanavg而不是fanin进行He初始化，则可以使用Variance Scaling初始化，如下所示：

```python
    init = keras.initializers.VarianceScaling(scale=2.,      mode='fan_avg', distribution='uniform')
    keras.layers.Dense(10, activation="relu", kernel_initializer=init)
```

### 11.1.2 非饱和激活函数

Glorot和Bengio在2010年的论文中提出的一项见解是，梯度不稳定的问题部分是**由于激活函数选择不当所致**。在此之前，大多数人都认为，如果大自然母亲选择在生物神经元中使用类似sigmoid的激活函数，那么它们必定是一个好选择。但是事实证明，其他激活函数在深度神经网络中的表现要好得多，尤其是ReLU激活函数，这主要是因为它对正值不饱和（并且计算速度很快）。

不幸的是，ReLU激活函数并不完美。它有一个被称为“濒死的ReLU”的问题：在训练过程中，某些神经元实际上“死亡”了，这意味着它们停止输出除0以外的任何值。在某些情况下，你可能会发现网络中一半的神经元都死了，特别是如果你使用较大的学习率。当神经元的权重进行调整时，其输入的加权和对于训练集中的所有实例均为负数，神经元会死亡。发生这种情况时，它只会继续输出零，梯度下降不会再影响它，因为**ReLU函数的输入为负时其梯度为零**。

要解决此问题，你可能需要使用ReLU函数的变体，例如leaky ReLU。该函数定义为$LeakyReLU_α(z)=max(αz,z)$（见图3）。超参数α定义函数“泄漏”的程度：它是z<0时函数的斜率，通常设置为0.01。这个小的斜率确保了leaky ReLU永远不会死亡。

它们可能会陷入长时间的昏迷，但是有机会最后醒来。2015年的一篇论文比较了ReLU激活函数的几种变体，其结论之一是泄漏的变体要好于严格的ReLU激活函数。实际上，设置α=0.2（大泄漏）似乎比α=0.01（小泄漏）会产生更好的性能。本论文还对随机的Leaky ReLU（RReLU）进行了评估，在训练过程中在给定范围内随机选择α，在测试过程中将其固定为平均值。RReLU的表现也相当不错，似乎可以充当正则化函数（减少了过拟合训练集的风险）。最后，本文评估了参数化leaky ReLU（PReLU），其中α可以在训练期间学习（不是超参数，它像其他任何参数一样，可以通过反向传播进行修改）。据报道，PReLU在大型图像数据集上的性能明显优于ReLU，但是在较小的数据集上，它存在过拟合训练集的风险。

![fig03_Leaky ReLU](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter11/figures/fig03_Leaky%20ReLU.jpg)

最后但并非最不重要的一点是，Djork-ArnéClevert等人在2015年发表的论文提出了一种新的激活函数，称为指数线性单位（Exponential Linear Unit，ELU），该函数在作者的实验中胜过所有ReLU变体：减少训练时间，神经网络在测试集上表现更好。图5绘制了函数图，公式11-2给出了其定义。

![fig04_公式11-2_ELU激活函数](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter11/figures/fig04_%E5%85%AC%E5%BC%8F11-2_ELU%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.jpg)

![fig05_ELU激活函数](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter11/figures/fig05_ELU%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.jpg)

ELU激活函数与ReLU函数非常相似，但有一些主要区别：

- 当z<0时，它取负值，这使该单元的平均输出接近于0，有助于缓解梯度消失的问题。超参数α定义一个值，该值为当z为较大负数时ELU函数逼近的值。通常将其设置为1，但是你可以像其他任何超参数一样对其进行调整。

- 对于z<0，它具有非零梯度，从而避免了神经元死亡的问题。

- 如果α等于1，则该函数在所有位置（包括z=0左右）都是平滑的，这有助于加速梯度下降，因为它在z=0的左右两侧弹跳不大。

ELU激活函数的主要缺点是它的计算比ReLU函数及其变体要慢（由于使用了指数函
数）。它在训练过程中更快的收敛速度弥补了这种缓慢的计算，但是在测试时，ELU网络将比ReLU网络慢。

然后，Günter Klambauer等人在2017年发表的论文提出了可扩展的ELU(Scaled ELU，SEIU）激活函数：顾名思义，它是ELU激活函数的可扩展变体。作者表明，如果你构建一个仅由密集层堆叠组成的神经网络，并且如果所有隐藏层都使用SELU激活函数，则该网络是自归一化的：每层的输出倾向于在训练过程中保留平均值0和标准差1，从而解决了梯度消失/梯度爆炸的问题。结果，SELU激活函数通常大大优于这些神经网络（尤其是深层神经网络）的其他激活函数。但是，有一些产生自归一化的条件（有关数学证明，请参见论文）：

- 输入特征必须是标准化的（平均值为0，标准差为1）。

- 每个隐藏层的权重必须使用LeCun正态初始化。在Keras中，这意味着设置`kernel_initializer="lecun_normal"`。

- 网络的架构必须是顺序的。不幸的是，如果你尝试在非顺序架构（例如循环网络）中使用SELU（见第15章）或具有跳过连接的网络（即在Wide&Deep网络中跳过层的连接），将无法保证自归一化，因此SELU不一定会胜过其他激活函数。

- 本论文仅在所有层都是密集层的情况下保证自归一化，但一些研究人员指出SELU激活函数也可以改善卷积神经网络的性能（见第14章）

那么，你应该对深度神经网络的隐藏层使用哪个激活函数呢？尽管你的目标会
有所不同，但通常SELU>ELU>leaky ReLU（及其变体）>ReLU>tanh>logistic。如果网络的架构不能自归一化，那么ELU的性能可能会优于SELU（因为SELU在z=0时不平滑）。如果你非常关心运行时延迟，那么你可能更喜欢leaky ReLU。如果你不想调整其他超参数，则可以使用Keras使用的默认α值（例如，leaky ReLU为0.3）。如果你有空闲时间和计算能力，则可以使用交叉验证来评估其他激活函数，例如，如果网络过拟合，则为RReLU；如果你的训练集很大，则为PReLU。也就是说，由于ReLU是迄今为止最常用的激活函数，因此许多库和硬件加速器都提供了ReLU特定的优化。因此，如果你将速度放在首位，那么ReLU可能仍然是最佳选择。要使用leaky ReLU激活函数，创建一个LeakyReLU层，并将其添加到你想要应用它的层之后的模型中：

对于PReLU，将LeakyRelu（alpha=0.2）替换为PReLU()。Keras当前没有RReLU的官方实现，但是你可以轻松地实现自己的（要了解如何实现，请参阅第12章末尾的练习）。

对于SELU激活，在创建层时设置`activation="selu"`和`kernel_initializer="lecun_normal"`：

### 11.1.3 批量归一化

尽管将He初始化与ELU（或ReLU的任何变体）一起使用可以显著减少在训练开始时的梯度消失/梯度爆炸问题的危险，但这并不能保证它们在训练期间不会再出现。

在2015年的一篇论文中，Sergey Ioffe和Christian Szegedy提出了一种称为批量归一化（BN）的技术来解决这些问题。该技术包括在模型中的每个隐藏层的激活函数之前或之后添加一个操作。该操作对每个输入零中心并归一化，然后每层使用两个新的参数向量缩放和偏移其结果：一个用于缩放，另一个用于偏移。换句话说，该操作可以使模型学习各层输入的最佳缩放和均值。在许多情况下，如果你将BN层添加为神经网络的第一层，则无须归一化训练集（例如，使用StandardScaler）；BN层会为你完成此操作（因为它一次只能查看一个批次，它还可以重新缩放和偏移每个输入特征）。

为了使输入零中心并归一化，该算法**需要估计每个输入的均值和标准差**。通过评估当前小批次上的输入的均值和标准差（因此称为“批量归一化”）来做到这一点。公式11-3逐步总结了整个操作。

![fig06_公式11-3_批量归一化算法](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter11/figures/fig06_%E5%85%AC%E5%BC%8F11-3_%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96%E7%AE%97%E6%B3%95.jpg)

此算法中：

- $\mu_B$是输入均值的向量，在整个小批量B上评估（每个输入包含一个均值）。

- $\sigma_B$是输入标准差的向量，也在整个小批量中进行评估（每个输入包含一个标准差）。

- $m_B$是小批量中的实例数量。

- $x_{(i)}$是实例i的零中心和归一化输入的向量。

- γ是该层的输出缩放参数向量（每个输入包含一个缩放参数）。

- ⊗表示逐元素乘法（每个输入乘以其相应的输出缩放参数）。

- β是层的输出移动（偏移）参数向量（每个输入包含一个偏移参数）。每个输入都通过其相应的移动参数进行偏移。

- ε是一个很小的数字以避免被零除（通常为10-5）。这称为平滑项。

- $z^{(i)}$是BN操作的输出。它是输入的缩放和偏移版本。

因此在训练期间，BN会归一化其输入，然后重新缩放并偏移它们。好！那在测试期间呢？这不那么简单。确实，我们可能需要对单个实例而不是成批次的实例做出预测：在这种情况下，我们无法计算每个输入的均值和标准差。而且，即使我们确实有一批次实例，它也可能太小，或者这些实例可能不是独立的和相同分布的，因此在这批实例上计算统计信息将是不可靠的。一种解决方法是等到训练结束，然后通过神经网络运行整个训练集，计算BN层每个输入的均值和标准差。然后，在进行预测时，可以使用这些“最终”的输入均值和标准差，而不是一个批次的输入均值和标准差。然而，大多数批量归一化的实现都是通过使用该层输入的均值和标准差的移动平均值来估计训练期间的最终统计信息。这是Keras在使用BatchNormalization层时自动执行的操作。综上所述，在每个批归一化层中学习了四个参数向量：通过常规反向传播学习γ（输出缩放向量）和β（输出偏移向量），和使用指数移动平均值估计的μ（最终的输入均值向量）和σ（最终输入标准差向量）。请注意，μ和σ是在训练期间估算的，但仅在训练后使用（以替换方程式11-3中的批量输入均值和标准差）。

Ioffe和Szegedy证明，批量归一化极大地改善了他们试验过的所有深度神经网络，从而极大地提高了ImageNet分类任务的性能（ImageNet是将图像分类为许多类的大型图像数据库，通常用于评估计算机视觉系统）。消失梯度的问题已大大减少，以至于它们可以使用饱和的激活函数，例如tanh甚至逻辑激活函数。网络对权重初始化也不太敏感。作者可以使用更大的学习率，大大加快了学习过程。它们特别指出：

批量归一化应用于最先进的图像分类模型，以少14倍的训练步骤即可达到相同的精度，在很大程度上击败了原始模型......使用批量归一化网络的集成，我们在ImageNet分类中改进了已发布的最好结果：前5位的验证错误达到了4.9％（和4.8％的测试错误），超过了人工评分者的准确性。

最后，就像不断赠送的礼物一样，批量归一化的作用就像正则化一样，减少了对其他正则化技术（如dropout，本章稍后将介绍）的需求。

但是，批量归一化确实增加了模型的复杂性（尽管它可以消除对输入数据进行归一化的需求，正如我们前面所讨论的）。此外，还有运行时间的损失：由于每一层都需要额外的计算，因此神经网络的预测速度较慢。幸运的是，经常可以在训练后将BN层与上一层融合，从而避免了运行时的损失。这是通过更新前一层的权重和偏置来完成的，以便它直接产生适当缩放和偏移的输出。例如，如果前一层计算$XW+b$，则BN层将计算$γ⊗(XW+b–μ)/σ+β$（忽略分母中的平滑项ε）。如果我们定义$W^′=γ⊗W/σ$和$b^′=γ⊗(b–μ)/σ+β$，则方程式可简化为$XW^′+b^′$。因此，如果我们用更新后的权重和偏置（$W^′$和$b^′$）替换前一层的权重和偏置（W和b），就可以去掉BN层（TFLite的优化器会自动执行此操作，请参阅第19章）。

你可能会发现训练相当慢，因为当你使用批量归一化时每个轮次要花费更多时间。通常情况下，这被BN的收敛速度要快得多的事实而抵消，因此达到相同性能所需的轮次更少，总而言之，墙上的时间通常会更短（这是墙上的时钟所测量的时间）。

#### 用Keras实现批量归一化

与使用Keras进行的大多数操作一样，实现批量归一化既简单又直观。只需在每个隐藏层的激活函数之前或之后添加一个BatchNormalization层，然后可选地在模型的第一层后添加一个BN层。例如，此模型在每个隐藏层之后作为模型的第一层（展平输入图像之后）应用BN：

```python
    model = keras.models.Sequential([
        keras.layers.Flatten(input_shape=[28, 28]),
        keras.layers.BatchNormalization(),
        keras.layers.Dense(300, activation="relu"),
        keras.layers.BatchNormalization(),
        keras.layers.Dense(100, activation="relu"),
        keras.layers.BatchNormalization(),
        keras.layers.Dense(10, activation="softmax")
    ])
```

就这样！在这个只有两个隐藏层的小示例中，批量归一化不可能产生非常积极的影响。但是对于更深层的网络，它可以带来巨大的改变。

如你所见，每个BN层的每个输入添加了四个参数：γ、β、μ和σ（例如，第一个BN层添加了3136个参数，即4×784）。最后两个参数μ和σ是移动平均值。它们不受反向传播的影响，因此Keras称其为“不可训练”（如果你计算BN参数的总数3136+1200+400，然后除以2，则得到2368，即此模型中不可训练参数的总数）。

让我们看一下第一个BN层的参数。两个是可训练的（通过反向传播），两个不是：

```python
    >>> [(var.name, var.trainable) for var in model.layers[1].variables]
    [('batch_normalization_v2/gamma:0', True),
    ('batch_normalization_v2/beta:0', True),
    ('batch_normalization_v2/moving_mean:0', False),
    ('batch_normalization_v2/moving_variance:0', False)]
```

现在，当你在Keras中创建BN层时，它还会创建两个操作，在训练期间的每次迭代中，Keras都会调用这两个操作。这些操作会更新移动平均值。由于我们使用的是TensorFlow后端，因此这些操作是TensorFlow操作（我们将在第12章中讨论TF操作）：

```python
    >>> model.layers[1].updates
    [<tf.Operation 'cond_2/Identity' type=Identity>,
    <tf.Operation 'cond_3/Identity' type=Identity>]
```

BN论文的作者主张在激活函数之前（而不是之后）添加BN层（就像我们刚才所做的那样）。关于此问题，存在一些争论，哪个更好取决于你的任务——你也可以对此进行试验，看看哪个选择最适合你的数据集。要在激活函数之前添加BN层，必须从隐藏层中删除激活函数，并将其作为单独的层添加到BN层之后。此外，由于批量归一化层的每个输入都包含一个偏移参数，因此你可以从上一层中删除偏置项（创建时只需传递use_bias=False即可）：

```python
    model = keras.models.Sequential([
        keras.layers.Flatten(input_shape=[28, 28]),
        keras.layers.BatchNormalization(),
        keras.layers.Dense(300, use_bias=False),
        keras.layers.BatchNormalization(),
        keras.layers.Activation("relu"),
        keras.layers.Dense(100, use_bias=False),
        keras.layers.BatchNormalization(),
        keras.layers.Activation("relu"),
        keras.layers.Dense(10, activation="softmax")
    ])
```

BatchNormalization类具有许多可以调整的超参数。默认值通常可以，但是你偶尔可能需要调整omentum。BatchNormalization层在更新指数移动平均值时使用此超参数。给定一个新值v（即在当前批次中计算的输入均值或标准差的新向量），该层使用以下公式来更新运行时平均$\hat v$：

$\hat v  \leftarrow \hat v \times momentum+v \times (1-momentum)$

一个良好的动量值通常接近1；例如0.9、0.99或0.999（对于较大的数据集和较小的批处理，你需要更多的9）。

另一个重要的超参数是axis：它确定哪个轴应该被归一化。默认为-1，这意味着默认情况下它将对最后一个轴进行归一化（使用跨其他轴计算得到的均值和标准差）。当输入批次为2D（即批次形状为[批次大小，特征]）时，这意味着将基于在批次中所有实例上计算得到的均值和标准差对每个输入特征进行归一化。例如，先前代码示例中的第一个BN层将独立地归一化（重新缩放和偏移）784个输入特征中的每一个。如果将第一个BN层移动到Flatten层之前，则输入批次将为3D，形状为[批次大小，高度，宽度]。因此，BN层将计算28个均值和28个标准差（每列像素1个，在批次中的所有实例以及在列中所有行之间计算），它将使用相同的均值和标准差对给定列中的所有像素进行归一化。也是只有28个缩放参数和28个偏移参数。相反，你如果仍然要独立的处理784个像素中的每一个，则应设置axis=[1，2]。

请注意，BN层在训练期间和训练后不会执行相同的计算：它在训练期间使用批处理统计信息，在训练后使用“最终”的统计信息（即移动平均的最终值）。让我们看一下这个类的源代码，看看如何处理：

```python
class BatchNormalization(keras.layers.Layer):
    [...]
    def call(self, inputs, training=None):
        [...]
```

如你所见，`call()`方法是执行计算的方法，它有一个额外的训练参数，默认情况下将其设置为None，但是在训练过程中`fit()`方法将其设置为1。如果你需要编写自定义层，它的行为在训练期间和测试期间必须有所不同，把一个训练参数添加到`call()`方法中，并在该方法中使用这个参数来决定要计算的内容（我们将在第12章中讨论自定义层）。

BatchNormalization已成为深度神经网络中最常用的层之一，以至于在图表中通常将其省略，因为假定在每层之后都添加了BN。但是Hongyi Zhang等人最近的论文可能会改变这一假设：通过使用一种新颖的fixed-update(fixup)权重初始化技术，作者设法训练了一个非常深的神经网络（10000层！），没有使用BN，在复杂的图像分类任务上实现了最先进的性能。但是，由于这是一项前沿研究，因此你在放弃批量归一化之前，可能需要等待其他研究来确认此发现。

### 11.1.4 梯度裁剪

缓解梯度爆炸问题的另一种流行技术是在反向传播期间裁剪梯度，使它们永远不会超过某个阈值。这称为梯度裁剪。这种技术最常用于循环神经网络，因为在RNN中难以使用批量归一化，正如我们将在第15章中看到的那样。对于其他类型的网络，BN通常就足够了。

在Keras中，实现梯度裁剪仅仅是一个在创建优化器时设置clipvalue或clipnorm参数的问题，例如：

```python
    optimizer = keras.optimizers.SGD(clipvalue=1.0)
    model.compile(loss="mse", optimizer=optimizer)
```

该优化器会将梯度向量的每个分量都裁剪为-1.0和1.0之间的值。这意味着所有损失的偏导数（相对于每个可训练的参数）将限制在-1.0和1.0之间。阈值是你可以调整的超参数。注意，它可能会改变梯度向量的方向。例如，如果原始梯度向量为[0.9，100.0]，则其大部分指向第二个轴的方向。但是按值裁剪后，将得到[0.9，1.0]，该点大致指向两个轴之间的对角线。实际上，这种方法行之有效。如果要确保“梯度裁剪”不更改梯度向量的方向，你应该通过设置clipnorm而不是clipvalue按照范数来裁剪。如果2范数大于你选择的阈值，则会裁剪整个梯度。例如，如果你设置clipnorm=1.0，则向量[0.9，100.0]将被裁剪为[0.00899964，0.9999595]，保留其方向，但几乎消除了第一个分量。如果你观察到了在训练过程中梯度爆炸（可以使用TensorBoard跟踪梯度的大小），可能要尝试使用两种方法（按值裁剪和按范数裁剪），看看哪个选择在验证集上表现更好。

## 11.2 重用预训练层

从头开始训练非常大的DNN通常不是一个好主意：相反，你应该总是试图找到一个现有的与你要解决的任务相似的神经网络（我们将在第14章讨论如何找到它们），然后重用该网络的较低层。此技术称为迁移学习。它不仅会大大加快训练速度，而且会大大减少训练数据。

假设你可以访问一个经过训练的DNN，将图片分成100个不同的类别，其中包括动物、植物、车辆和日常物品。你现在想训练DNN来对特定类型的车辆进行分类。这些任务非常相似，甚至部分有重叠，因此你应该尝试重用第一个网络的一部分（见图7）。

![fig07_重用预训练层](https://github.com/Vuean/Hands-On-ML/blob/main/Chapter11/figures/fig07_%E9%87%8D%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E5%B1%82.jpg)

如果新任务的输入图片的大小与原始任务中使用的图片不同，通常必须添加预处理步骤将其调整为原始模型所需的大小。一般而言，当输入具有类似的低级特征时，迁移学习最有效。

通常应该替换掉原始模型的输出层，因为它对于新任务很有可能根本没有用，甚至对于新任务而言，可能没有正确数量的输出。

类似地，原始模型的上部分隐藏层不太可能像下部分那样有用，因为对新任务最有用的高级特征可能与对原始任务最有用的特征有很大的不同。你需要找到正确的层数来重用。

任务越相似，可重用的层越多（从较低的层开始）。对于非常相似的任务，请尝试保留所有的隐藏层和只是替换掉输出层。

首先尝试冻结所有可重复使用的层（使其权重不可训练，这样梯度下降就不会对其进行修改），训练模型并查看其表现。然后尝试解冻上部隐藏层中的一两层，使反向传播可以对其进行调整，再查看性能是否有所提高。你拥有的训练数据越多，可以解冻的层就越多。当解冻重用层时，降低学习率也很有用，可以避免破坏其已经调整好的权重。

如果你仍然无法获得良好的性能，并且你的训练数据很少，试着去掉顶部的隐藏层，然后再次冻结所有其余的隐藏层。你可以进行迭代，直到找到合适的可以重复使用的层数。如果你有大量的训练数据，则可以尝试替换顶部的隐藏层而不是去掉它们，你甚至可以添加更多的隐藏层。

### 11.2.1 用Keras进行迁移学习

让我们看一个示例。假设Fashion MNIST数据集仅包含8个类别，例如，除凉鞋和衬衫之外的所有类别。有人在该数据集上建立并训练了Keras模型，并获得了相当不错的性能（精度>90％）。我们将此模型称为A。你现在要处理另一项任务：你有凉鞋和衬衫的图像，想要训练一个二元分类器（正=衬衫，负=凉鞋）。你的数据集非常小，只有200张带标签的图像。当你使用与模型A相同的架构训练一个新模型（称为模型B）时，它的性能相当好（97.2％的精度）。但是由于这是一项容易得多的任务（只有两个类），所以你希望有更多。喝早茶时，你意识到你的任务与任务A非常相似，也许通过迁移学习可以有所帮助？让我们找出答案！

首先，你需要加载模型A并基于该模型的层创建一个新模型。让我们重用除输出层之外的所有层：

```python
    model_A = keras.models.load_model("my_model_A.h5")
    model_B_on_A = keras.models.Sequential(model_A.layers[:-1])
    model_B_on_A.add(keras.layers.Dense(1, activation="sigmoid"))
```

请注意，model_A和model_B_on_A现在共享一些层。当训练odel_B_on_A时，也会影响model_A。如果想避免这种情况，需要在重用model_A的层之前对其进行克隆。为此，请使用clone_model()来克隆模型A的架构，然后复制其权重（因为clone_model()不会克隆权重）

```python
    model_A_clone = keras.models.clone_model(model_A)
    model_A_clone.set_weights(model_A.get_weights())
```

现在你可以为任务B训练model_B_on_A，但是由于新的输出层是随机初始化的，它会产生较大的错误（至少在前几个轮次内），因此将存在较大的错误梯度，这可能会破坏重用的权重。为了避免这种情况，一种方法是在前几个轮次时冻结重用的层，给新层一些时间来学习合理的权重。为此，请将每一层的可训练属性设置为False并编译模型：

```python
    for layer in model_B_on_A.layers[:-1]:
        layer.trainable = False

    model_B_on_A.compile(loss="binary_crossentropy",
                        optimizer=keras.optimizers.SGD(lr=1e-3),
                        metrics=["accuracy"])
```

冻结或解冻层后，你必须总是要编译模型。

现在，你可以训练模型几个轮次，然后解冻重用的层（这需要再次编译模型），并继续进行训练来微调任务B的重用层。解冻重用层之后，降低学习率通常是个好主意，可以再次避免损坏重用的权重：

```python
        history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,
                            validation_data=(X_valid_B, y_valid_B))

    for layer in model_B_on_A.layers[:-1]:
        layer.trainable = True

    model_B_on_A.compile(loss="binary_crossentropy",
                        optimizer=keras.optimizers.SGD(lr=1e-3),
                        metrics=["accuracy"])
    history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,
                            validation_data=(X_valid_B, y_valid_B))
```

那么，最终结果是什么？好了，该模型的测试精度为99.25％，这意味着迁移学习将错误率从2.8％降低到了几乎0.7％！那是四倍的差距！

```python
    model_B_on_A.evaluate(X_test_B, y_test_B)
        >>> 63/63 [==============================] - 0s 667us/step - loss: 0.0684 - accuracy: 0.9935
    [0.06837236881256104, 0.9934999942779541]
```

你被说服了吗？你不应该：我作弊了！我尝试了许多配置，直到发现一个有明显改进的配置。如果你试着更改类别或随机种子，会发现改进通常会下降，甚至消失或反转。我所做的就是“折磨数据直到信服为止”。当论文看起来过于优秀时，你应该要怀疑：也许这个浮华的新技术实际上并没有多大帮助（事实上，它甚至可能降低性能），但作者尝试了许多变体，仅报告了最好的结果（这可能是由于运气所致），而没有提及他们在途中遇到了多少次失败。在大多数情况下，这根本不是恶意的，但这是造成如此多的科学结果永远无法复现的部分原因。

我为什么要作弊？事实证明，迁移学习在小型密集型网络中不能很好地工作，大概是因为小型网络学习的模式很少，密集网络学习的是非常特定的模式，这在其他任务中不是很有用。迁移学习最适合使用深度卷积神经网络，该神经网络倾向于学习更为通用的特征检测器（尤其是在较低层）。我们将在第14章中使用刚刚讨论的技术重新审视迁移学习（我保证，这一次不会作弊！）。

### 11.2.2 无监督预训练

P339
